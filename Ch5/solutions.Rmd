---
title: "Untitled"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ISLR)
library(boot)
library(ISLR2)
```


# Question 5 

> In Chapter 4, we used logistic regression to predict the probability of
> `default` using `income` and `balance` on the `Default` data set. We will now
> estimate the test error of this logistic regression model using the
> validation set approach. Do not forget to set a random seed before beginning
> your analysis.

```{r}
set.seed(990215)
```

> a. Fit a logistic regression model that uses `income` and `balance` to predict
>    `default`.

```{r}
log_model <- glm(default ~ income + balance,
                 data = Default,
                 family = "binomial")
```


> b. Using the validation set approach, estimate the test error of this model.
>    In order to do this, you must perform the following steps:
>
>    i. Split the sample set into a training set and a validation set.

```{r}
obs <- nrow(Default)
train <- sample(obs, obs/2)
```

>    ii. Fit a multiple logistic regression model using only the training
>    observations.

```{r}
log_model_cv <- glm(default ~ income + balance,
                 data = Default,
                 family = "binomial",
                 subset = train)
```

>    iii. Obtain a prediction of default status for each individual in
>    the validation set by computing the posterior probability of
>    default for that individual, and classifying the individual to
>    the `default` category if the posterior probability is greater
>    than 0.5.

```{r}
probs <- predict(log_model_cv, newdata = Default[-train,], type = "response")
preds <- ifelse(probs > .5, "Yes", "No")
```

>    iv. Compute the validation set error, which is the fraction of
>    the observations in the validation set that are misclassified.


```{r}
mean(preds != Default$default)
```

> c. Repeat the process in (b) three times, using three different splits of the
>    observations into a training set and a validation set. Comment on the
>    results obtained.

```{r}
result <- c()
for (i in 1:3) {
    train <- sample(obs, obs / 2)
    log_model_cv <- glm(
        default ~ income + balance,
        data = Default,
        family = "binomial",
        subset = train
    )
    preds <-
        ifelse(predict(log_model_cv,
                       newdata = Default[-train, ],
                       type = "response") > 0.5,
               "Yes",
               "No")
    result <- c(result, mean(preds != Default$default[-train]))
}
result
```

> d. Now consider a logistic regression model that predicts the probability of
>    `default` using `income`, `balance`, and a dummy variable for `student`.
>    Estimate the test error for this model using the validation set approach.
>    Comment on whether or not including a dummy variable for `student` leads to
>    a reduction in the test error rate.

Appears to be no significant difference in including `student`.

```{r}
train <- sample(obs, obs / 2)
log_model_cv <- glm(
    default ~ income + balance + student,
    data = Default,
    family = "binomial",
    subset = train
)
preds <-
    ifelse(predict(log_model_cv,
                   newdata = Default[-train,],
                   type = "response") > 0.5,
           "Yes",
           "No")
mean(preds != Default$default[-train])
```

# Question 6

> We continue to consider the use of a logistic regression model to predict the
> probability of `default` using `income` and `balance` on the `Default` data
> set. In particular, we will now compute estimates for the standard errors of
> the `income` and `balance` logistic regression coefficients in two different
> ways: (1) using the bootstrap, and (2) using the standard formula for
> computing the standard errors in the `glm()` function. Do not forget to set a
> random seed before beginning your analysis.

> a. Using the `summary()` and `glm()` functions, determine the estimated
>    standard errors for the coefficients associated with `income` and
>    `balance` in a multiple logistic regression model that uses both
>    predictors.


```{r}
set.seed(021599)
model <- glm(
    default ~ income + balance,
    data = Default,
    family = "binomial"
)
summary(model)$coef
```

> b. Write a function, `boot.fn()`, that takes as input the `Default` data set
>    as well as an index of the observations, and that outputs the coefficient
>    estimates for `income` and `balance` in the multiple logistic regression
>    model.

```{r}
boot.fn <- function(Default, index) {
    model <- glm(default ~ income + balance,
                 data = Default[index,],
                 family = "binomial")
    summary(model)$coef[,1]
}
```

> c. Use the `boot()` function together with your `boot.fn()` function to
>    estimate the standard errors of the logistic regression coefficients for
>    income and balance.

```{r}
boot(Default, boot.fn, 1000)
```

> d. Comment on the estimated standard errors obtained using the `glm()`
>    function and using your bootstrap function.

Very similar results

# Question 7

> In Sections 5.3.2 and 5.3.3, we saw that the `cv.glm()` function can be used
> in order to compute the LOOCV test error estimate. Alternatively, one could
> compute those quantities using just the `glm()` and `predict.glm()`
> functions, and a for loop. You will now take this approach in order to
> compute the LOOCV error for a simple logistic regression model on the `Weekly`
> data set. Recall that in the context of classification problems, the LOOCV
> error is given in (5.4).


> a. Fit a logistic regression model that predicts `Direction` using `Lag1` and
>    `Lag2`.

```{r}
model <- glm(Direction ~ Lag1 + Lag2, data = Weekly, family = "binomial")
```

> b. Fit a logistic regression model that predicts `Direction` using `Lag1` and
>    `Lag2` _using all but the first observation_.

```{r}
model_loo <-
    glm(Direction ~ Lag1 + Lag2, data = Weekly[-1, ], family = "binomial")
```

> c. Use the model from (b) to predict the direction of the first
>    observation. You can do this by predicting that the first observation will
>    go up if $P($`Direction="Up" | Lag1 , Lag2`$) > 0.5$. Was this observation
>    correctly classified?

It was correct.

```{r}
predict(model_loo, newdata = Weekly[1, ], type = "response")
```



> d. Write a for loop from $i = 1$ to $i = n$, where $n$ is the number of
>    observations in the data set, that performs each of the following steps:
>    i.   Fit a logistic regression model using all but the $i$th observation
>         to predict `Direction` using `Lag1` and `Lag2` .
>    ii.  Compute the posterior probability of the market moving up
>         for the $i$th observation.
>    iii. Use the posterior probability for the $i$th observation in order
>         to predict whether or not the market moves up.
>    iv.  Determine whether or not an error was made in predicting the
>         direction for the $i$th observation. If an error was made, then
>         indicate this as a 1, and otherwise indicate it as a 0.

```{r}
n <- nrow(Weekly)
res <- c()
for (i in 1:n) {
    fit <- glm(Direction ~ Lag1 + Lag2,
               data =  Weekly[-i, ],
               family = "binomial")
    prob <- predict(fit, newdata = Weekly[i,], type = "response")
    pred <- ifelse(prob > .5, "Up", "Down")
    res <- c(res, as.numeric(pred == Weekly[i,]$Direction))
}
```

> e. Take the average of the $n$ numbers obtained in (d) in order to obtain the
>    LOOCV estimate for the test error. Comment on the results.

We are correct 55% of the time. Which is not much better than a random walk.

```{r}
mean(res)
```

# Question 8

> We will now perform cross-validation on a simulated data set.

> a. Generate a simulated data set as follows:
>    ```r
>    > set.seed(1)
>    > x <- rnorm(100)
>    > y <- x - 2 *x^2 + rnorm(100)
>    ```
>    In this data set, what is $n$ and what is $p$? Write out the model
>    used to generate the data in equation form.

```{r}
set.seed(1)
x <- rnorm(100)
y <- x - 2 *x^2 + rnorm(100)

```

$$
n = 100 \\
p = 1 \\
Y = X - 2X^2 + \epsilon
$$

> b. Create a scatterplot of $X$ against $Y$. Comment on what you find.

Non-linear. Looks quadratic.

```{r}
plot(y~x)
```

> c. Set a random seed, and then compute the LOOCV errors that result from
>    fitting the following four models using least squares:
>    i.   $Y = \beta_0 + \beta_1 X + \epsilon$
>    ii.  $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \epsilon$
>    iii. $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \epsilon$
>    iv.  $Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \beta_4 X^4 + \epsilon$.
>
>    Note you may find it helpful to use the `data.frame()` function
>    to create a single data set containing both $X$ and $Y$.

```{r}
set.seed(029915)
cv_error <- rep(0, 4)
df <- data.frame(y, x)
for (i in 1:4) {
    fit <- glm(y ~ poly(x, i), data = df)
    cv_error[i] <- cv.glm(df, fit)$delta[1]
}
cv_error
```

> d. Repeat (c) using another random seed, and report your results.
>    Are your results the same as what you got in (c)? Why?

Same. Because we the same "folds" (all of the observations) will be included in both cv-process.

```{r}
set.seed(1999)
cv_error <- rep(0, 4)
df <- data.frame(y, x)
for (i in 1:4) {
    fit <- glm(y ~ poly(x, i), data = df)
    cv_error[i] <- cv.glm(df, fit)$delta[1]
}
cv_error
```

> e. Which of the models in (c) had the smallest LOOCV error? Is this what you
>    expected? Explain your answer.

The 2-degree polynomial. It was expected both given the visualization and knowing the actual formula for the data.


> f. Comment on the statistical significance of the coefficient estimates
>    that results from fitting each of the models in (c) using least squares.
>    Do these results agree with the conclusions drawn based on the
>    cross-validation results?

It is in line with our previous observaitons.

```{r}
summary(glm(y ~ poly(x, 1), data = df))$coef
summary(glm(y ~ poly(x, 2), data = df))$coef
summary(glm(y ~ poly(x, 3), data = df))$coef
summary(glm(y ~ poly(x, 4), data = df))$coef
```

# Question 9

> We will now consider the `Boston` housing data set, from the `ISLR2`
> library.

> a.  Based on this data set, provide an estimate for the population mean of
>    `medv`. Call this estimate $\hat\mu$.

```{r}
mean(Boston$medv)
```

> b.  Provide an estimate of the standard error of $\hat\mu$. Interpret this
>    result.
>
>    _Hint: We can compute the standard error of the sample mean by
>    dividing the sample standard deviation by the square root of the number of
>    observations._

```{r}
sd(Boston$medv) / sqrt(nrow(Boston))
```

> c.  Now estimate the standard error of $\hat\mu$ using the bootstrap. How does
>    this compare to your answer from (b)?

Very similar result.

```{r}
boot.fn <- function(data, i) {
    boot_sample <- sample(Boston$medv, nrow(Boston), replace = T)
    mean(boot_sample)
}
b <- boot(Boston$medv, boot.fn, R = 1000)
b
```



> d.  Based on your bootstrap estimate from (c), provide a 95% confidence
>    interval for the mean of `medv`. Compare it to the results obtained using
>    `t.test(Boston$medv)`.
>
>    _Hint: You can approximate a 95% confidence interval using the
>    formula $[\hat\mu - 2SE(\hat\mu),  \hat\mu + 2SE(\hat\mu)].$_

```{r}
b$t0 - 2*0.405298
b$t0 + 2*0.405298

t.test(Boston$medv)
```

> e.  Based on this data set, provide an estimate, $\hat\mu_{med}$, for the
>    median value of `medv` in the population.

```{r}
median(Boston$medv)
```


> f.  We now would like to estimate the standard error of $\hat\mu_{med}$.
>    Unfortunately, there is no simple formula for computing the standard error
>    of the median. Instead, estimate the standard error of the median using
>    the bootstrap. Comment on your findings.

The estimated s.e. of the median is lower than the estimated s.e. of the mean.

```{r}
boot.fn <- function(data, i) {
    boot_sample <- sample(data$medv, nrow(data), replace = T)
    median(boot_sample)
}
boot(Boston, boot.fn, R= 1000)
```

> g.  Based on this data set, provide an estimate for the tenth percentile of
>    `medv` in Boston census tracts. Call this quantity $\hat\mu_{0.1}$. (You
>    can use the `quantile()` function.)

```{r}
quantile(Boston$medv, 0.1)
```

> h.  Use the bootstrap to estimate the standard error of $\hat\mu_{0.1}$.
>    Comment on your findings.

The standard error is the highest among all the other estimated quantities.

```{r}
boot.fn <- function(data, x) {
    boot_sample <- sample(data$medv, nrow(data), replace = T)
    quantile(boot_sample, .1)
}
boot(Boston, boot.fn, R=1000)
```


